__all__ = [
    "Pipeline",
    "PipelineStep",
    "DescribableOperation",
    "ProvCompatibleOperation",
]

import dataclasses
from typing import Dict, List, Optional, Protocol, Tuple, Union, runtime_checkable
import warnings

from medkit.core.annotation import Annotation
from medkit.core.document import Document
from medkit.core.id import generate_id
from medkit.core.operation import (
    OperationDescription,
    ProcessingOperation,
)
from medkit.core.prov_builder import ProvBuilder


@runtime_checkable
class ProvCompatibleOperation(Protocol):
    def set_prov_builder(self, prov_builder: ProvBuilder):
        pass


@runtime_checkable
class DescribableOperation(Protocol):
    description: OperationDescription


@dataclasses.dataclass
class PipelineStep:
    """`Pipeline` item describing how a processing operation is connected to other

    Attributes
    ----------
    operation:
        The operation to use at that step
    input_keys:
        For each input of `operation`, the key to use to retrieve the
        correspoding annotations (either retrieved from a document
        or generated by an earlier pipeline step)
    output_keys:
        For each output of `operation`, the key used to pass output annotations
        to the next Pipeline step. Can be empty if `operation` doesn't return
        new annotations.
    """

    operation: ProcessingOperation
    input_keys: List[str]
    output_keys: List[str]


class Pipeline(ProcessingOperation):
    """Graph of processing operations

    A pipeline is made of pipeline steps, connecting together different processing
    operations by the use of input/output keys. Each operation can be seen as a node
    and the keys are its edge. Two operations can be chained by using the same string
    as an output key for the first operation and as an input key to the second.

    Steps must be added in the order of execution, there isn't any sort of depency
    detection mechanism.
    """

    def __init__(
        self,
        steps: List[PipelineStep],
        input_keys: List[str],
        output_keys: List[str],
        id: Optional[str] = None,
    ):
        """Initialize the pipeline

        Params
        ------
        steps:
            List of pipeline steps

            Steps will be executed in the order in which they were added,
            so make sure to add first the steps generating data used by other steps.

        input_keys:
            List of keys corresponding to the inputs passed to `process()`

        output_keys:
            List of keys corresponding to the outputs returned by `process()`
        """
        if id is None:
            id = generate_id()

        self.id: str = id
        self.steps: List[PipelineStep] = steps
        self.input_keys: List[str] = input_keys
        self.output_keys: List[str] = output_keys

        self._doc: Optional[Document] = None
        self._prov_builder: Optional[ProvBuilder] = None
        self._sub_prov_builder: Optional[ProvBuilder] = None

    @property
    def description(self) -> OperationDescription:
        steps_config = [
            dict(
                operation=s.operation.description
                if isinstance(s.operation, DescribableOperation)
                else None,
                input_keys=s.input_keys,
                output_keys=s.output_keys,
            )
            for s in self.steps
        ]
        config = dict(
            steps=steps_config,
            input_keys=self.input_keys,
            output_keys=self.output_keys,
        )
        return OperationDescription(
            id=self.id, name=self.__class__.__name__, config=config
        )

    def set_prov_builder(self, prov_builder: ProvBuilder):
        self._prov_builder = prov_builder
        self._sub_prov_builder = ProvBuilder()
        for step in self.steps:
            if not isinstance(step.operation, ProvCompatibleOperation):
                raise TypeError(
                    "Some operations in the pipeline steps are not"
                    " provenance-compatible"
                )
            step.operation.set_prov_builder(self._sub_prov_builder)

    def set_doc(self, doc: Document):
        self._doc = doc
        for step in self.steps:
            if isinstance(step.operation, Pipeline):
                step.operation.set_doc(doc)

    def process(
        self, *all_input_anns: List[Annotation]
    ) -> Union[None, List[Annotation], Tuple[List[Annotation], ...]]:
        if len(all_input_anns) != len(self.input_keys):
            raise RuntimeError(
                f"Number of input ({len(all_input_anns)}) does not match number of"
                f" input keys ({len(self.input_keys)})"
            )

        anns_by_key = dict(zip(self.input_keys, all_input_anns))
        for step in self.steps:
            self._perform_step(step, anns_by_key)

        all_output_anns = tuple(anns_by_key[key] for key in self.output_keys)

        if self._prov_builder is not None:
            self._add_provenance(all_output_anns)

        if len(all_output_anns) == 0:
            # no output
            return all_output_anns
        elif len(all_output_anns) == 1:
            # unwrap out of tuple if only 1 output
            return all_output_anns[0]
        else:
            return all_output_anns

    def _perform_step(self, step: PipelineStep, anns_by_key: Dict[str, Annotation]):
        # find annotations to feed to operation
        all_input_anns = []
        for input_key in step.input_keys:
            input_anns = anns_by_key.get(input_key)
            if input_anns is None:
                message = f"No annotations found for input key {input_key}"
                if any(input_key in s.output_keys for s in self.steps):
                    message += (
                        "Did you add the steps in the correct order in the pipeline?"
                    )
                raise RuntimeError(message)
            all_input_anns.append(input_anns)

        # call operation
        all_output_anns = step.operation.process(*all_input_anns)

        # wrap output in tuple if necessary
        # (operations performing in-place modifications
        # have no output and return None,
        # operations with single output may return a
        # single list instead of a tuple of lists)
        if all_output_anns is None:
            all_output_anns = tuple()
        elif not isinstance(all_output_anns, tuple):
            all_output_anns = (all_output_anns,)

        if len(all_output_anns) != len(step.output_keys):
            raise RuntimeError(
                f"Number of outputs ({len(all_output_anns)}) does not match number of"
                f" output keys ({len(step.output_keys)})"
            )

        # store output annotations
        if self._doc is None:
            warnings.warn(
                "Pipeline doesn't have a document on which to save annotations and"
                " operations"
            )
        else:
            if isinstance(step.operation, DescribableOperation):
                self._doc.add_operation(step.operation.description)

        for output_key, output_anns in zip(step.output_keys, all_output_anns):
            if output_key not in anns_by_key:
                anns_by_key[output_key] = output_anns
            else:
                anns_by_key[output_key] += output_anns

            # no need to add annotations to doc if operation is also a Pipeline
            # because in that case the operation has already been added
            if self._doc is not None and not isinstance(step.operation, Pipeline):
                for ann in output_anns:
                    self._doc.add_annotation(ann)

    def _add_provenance(self, all_output_anns: Tuple[List[Annotation], ...]):
        assert self._prov_builder is not None and self._sub_prov_builder is not None

        # flatten all output anns to have a list of data items generated by this pipeline
        anns = [ann for output_anns in all_output_anns for ann in output_anns]
        data_item_ids = [a.id for a in anns]
        self._prov_builder.add_prov_from_sub_graph(
            data_item_ids, self.id, self._sub_prov_builder
        )

    def check_sanity(self):
        steps_input_keys = [k for s in self.steps for k in s.input_keys]
        for input_key in self.input_keys:
            if input_key not in steps_input_keys:
                raise Exception(
                    f"Pipeline input key {input_key} does not correspond to any"
                    " step input key"
                )

        steps_output_keys = [k for s in self.steps for k in s.output_keys]
        for output_key in self.output_keys:
            if output_key not in steps_output_keys:
                raise Exception(
                    f"Pipeline output key {output_key} does not correspond to any"
                    " step output key"
                )

        for step in self.steps:
            for input_key in step.input_keys:
                if (
                    input_key not in steps_output_keys
                    and input_key not in self.input_keys
                ):
                    raise Exception(
                        f"Step input key {input_key} does not correspond to any step"
                        " output key nor any pipeline input key"
                    )

        available_keys = self.input_keys.copy()
        for step in self.steps:
            for input_key in step.input_keys:
                if input_key not in available_keys:
                    raise Exception(
                        f"Step input key {input_key} is not available yet at this step"
                    )
            available_keys += step.output_keys
